# Universal Research Paper OCR Pipeline

A production-ready Python backend script that converts research papers and academic documents from PDF to structured Markdown format. Features Mistral OCR API integration with an advanced AI-powered formatting pipeline designed to work across all research disciplines while preserving author intent and ensuring zero information loss.

## Features

- **üöÄ Unified Pipeline**: Single command processing - run the entire 4-stage pipeline with one command
- **Universal Research Paper Support**: Works across all academic disciplines (Life Sciences, Computer Science, Physics, Social Sciences, etc.)
- **Mistral OCR Integration**: High-quality OCR extraction using Mistral AI's latest OCR model
- **Intelligent Document Processing**: Auto-detects PDF filenames and creates organized output folders
- **Advanced AI Formatting**: Universal research prompt that adapts to different paper styles and conventions
- **Zero Information Loss**: Preserves 100% of original content while improving formatting
- **Mathematical Expression Repair**: Fixes LaTeX formulas, citations, and scientific notation
- **Figure & Table Processing**: Proper caption formatting and table reconstruction
- **Error Handling**: Comprehensive retry logic and fallback mechanisms
- **Flexible Input Options**: Process from URLs or local PDF files
- **Progress Tracking**: Real-time progress updates and detailed logging for each processing stage

## Quick Start

### 1. Clone the repository
```bash
git clone <your-repo-url>
cd ocr_script_own
```

### 2. Set up virtual environment
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 3. Install dependencies
```bash
pip install -r txtfiles/requirements.md
```

### 4. Configure environment variables
Copy the environment template and add your API keys:
```bash
cp txtfiles/env_template.md .env
# Edit .env and add your API keys:
# - MISTRAL_API_KEY (for OCR processing)
# - GEMINI_API_KEY (for advanced formatting)
```

### 5. Run the Complete Pipeline (Unified Script)
**NEW: Single Command Processing** - Run the entire pipeline with one command:
```bash
# Process a local PDF file
python unified_pipeline.py test_pdf/bio_paper_1.pdf

# Process from a URL
python unified_pipeline.py https://example.com/paper.pdf

# Process with custom output directory
python unified_pipeline.py test_pdf/bio_paper_1.pdf my_custom_folder
```

**The unified script automatically runs all 4 stages:**
1. ‚úÖ PDF Processing (OCR extraction)
2. ‚úÖ Image Link Fixing 
3. ‚úÖ Stage 1 Preprocessing
4. ‚úÖ Stage 2 LLM Formatting

### Alternative: Manual Step-by-Step Processing
If you prefer to run each stage individually:
```bash
# Step 1: PDF Processing
python ocr_get/process_pdf.py test_pdf/your_paper.pdf

# Step 2: Fix image links (auto-detects most recent folder)
python ocr_fix/fix_markdown.py

# Step 3: Stage 1 preprocessing and OCR fixes
python ocr_fix/stage1.py

# Step 4: Stage 2 universal research paper formatting
python ocr_fix/stage2.py
```

## Complete Process Flow

### Step 1: PDF Processing (`ocr_get/process_pdf.py`)
- **Input**: PDF document from URL, local file, or interactive selection
- **Process**: 
  - Auto-detects PDF filename and creates organized output folder (e.g., `demo_paper_2/`)
  - Calls Mistral OCR API with `mistral-ocr-latest` model
  - Extracts markdown content with high accuracy
  - Saves images as base64-encoded files with format detection (JPEG/PNG/GIF)
  - Handles complex academic content (equations, tables, figures)
- **Output**: 
  - `{pdf_name}/document_content.md` (raw OCR output)
  - `{pdf_name}/page_X_image_Y.{format}` (extracted images)

### Step 2: Image Link Fixing (`ocr_fix/fix_markdown.py`)
- **Input**: `{pdf_name}/document_content.md`
- **Process**: 
  - Auto-detects most recent output folder
  - Matches image tags with saved image files
  - Fixes image references for proper markdown display
- **Output**: `{pdf_name}/pre_stage_1.md`

### Step 3: Stage 1 Preprocessing (`ocr_fix/stage1.py`)
- **Input**: `{pdf_name}/pre_stage_1.md`
- **Process**:
  - **Universal Document Truncation**: Intelligently removes post-references content (acknowledgments, author affiliations, etc.) while adapting to different paper structures
  - **Enhanced OCR Error Fixes**: Repairs common OCR artifacts including:
    - Spacing issues: `https: //` ‚Üí `https://`
    - Ligature fixes: `Ô¨Å` ‚Üí `fi`, `Ô¨Ç` ‚Üí `fl`
    - Mathematical expressions: `{{ }}^{{133}}` ‚Üí `^133`
  - **Hybrid Paragraph Reconstruction**: Uses advanced regex pattern detection with line-by-line processing to:
    - Intelligently join broken paragraphs while preserving structural elements
    - Detect comprehensive range of markdown elements (headings, lists, tables, citations, figures)
    - Maintain precise control over paragraph buffering and formatting
  - **Zero Information Loss**: Preserves all original research content in main document body
- **Output**: `{pdf_name}/stage_1_complete.md`

### Step 4: Universal Research Formatting (`ocr_fix/stage2.py`)
- **Input**: `{pdf_name}/stage_1_complete.md`
- **Process**:
  - **Universal Research Prompt**: Adapts to different academic disciplines and styles using `txtfiles/universal_research_prompt.md`
  - **Section-by-Section Processing**: Intelligently splits document into logical sections for optimal LLM processing
  - **Mathematical Expression Repair**: Fixes LaTeX formulas and scientific notation (e.g., `$^{133}$` ‚Üí `<sup>133</sup>`)
  - **Citation Enhancement**: Repairs reference formatting while preserving author style (`^{11--13,26,19,38}` ‚Üí `^11-13,19,26,38`)
  - **Scientific Content Formatting**: Species names, chemical formulas, gene names (`SCGB3A2` ‚Üí `*SCGB3A2*`)
  - **Figure/Table Processing**: Creates proper figure references (`![Figure 1](#figure-1)`)
  - **Cross-Reference Creation**: Internal document linking and navigation
  - **Style Preservation**: Maintains author's original formatting preferences
  - **Intelligent Error Handling**: 3-attempt retry logic with exponential backoff and fallback to preserve content
- **Output**: `{pdf_name}/final_formatted.md`

## Configuration

### Environment Variables

Create a `.env` file with the following variables:

```env
# Mistral AI API Configuration
MISTRAL_API_KEY=your_mistral_api_key_here

# Google Gemini API Configuration
GEMINI_API_KEY=your_gemini_api_key_here

# Directory Configuration
UPLOAD_DIR=temp_uploads
EXTRACTED_IMAGES_DIR=extracted_images

# API Configuration
HOST=0.0.0.0
PORT=8000
```

## Usage

### Unified Pipeline (Recommended)

The easiest way to process documents is using the unified pipeline script:

```bash
# Activate virtual environment first
source venv/bin/activate

# Process a local PDF file
python unified_pipeline.py test_pdf/bio_paper_1.pdf

# Process from a URL
python unified_pipeline.py https://example.com/research_paper.pdf

# Process with custom output directory
python unified_pipeline.py test_pdf/bio_paper_1.pdf custom_output_folder
```

The unified script provides:
- ‚úÖ **Automated processing**: Runs all 4 stages sequentially
- ‚úÖ **Progress tracking**: Real-time updates for each stage
- ‚úÖ **Error handling**: Stops on errors with detailed messages
- ‚úÖ **Environment validation**: Checks API keys and dependencies
- ‚úÖ **File verification**: Confirms each stage completes successfully

### Manual Processing (Individual Scripts)

If you prefer to run each stage individually, the individual processing scripts support multiple input methods:

**Interactive Mode (Recommended)**:
```bash
python ocr_get/process_pdf.py
# Displays a menu to choose between URL input or local file selection
```

**Direct URL Processing**:
```bash
python ocr_get/process_pdf.py https://example.com/research_paper.pdf
```

**Local PDF Processing**:
```bash
python ocr_get/process_pdf.py test_pdf/my_paper.pdf
# Automatically creates output folder named "my_paper/"
```

**Custom Output Directory**:
```bash
python ocr_get/process_pdf.py test_pdf/paper.pdf custom_output_folder/
```

All methods automatically create output folders based on the PDF filename (e.g., `demo_paper_2.pdf` ‚Üí `demo_paper_2/` folder).

### Running the Complete Pipeline

```bash
# 1. Process PDF and extract content
python ocr_get/process_pdf.py

# 2. Fix image links in markdown
python ocr_fix/fix_markdown.py

# 3. Run Stage 1 preprocessing
python ocr_fix/stage1.py

# 4. Run Stage 2 advanced formatting
python ocr_fix/stage2.py
```

### Custom File Paths

All scripts support custom input/output paths:

```bash
# Stage 1 with custom paths
python ocr_fix/stage1.py input.md output.md

# Stage 2 with custom paths
python ocr_fix/stage2.py input.md output.md prompt.md
```

## Project Structure

```
ocr_script_own/
‚îú‚îÄ‚îÄ unified_pipeline.py         # üöÄ NEW: Single command for complete pipeline
‚îú‚îÄ‚îÄ ocr_get/                    # OCR processing tools
‚îÇ   ‚îú‚îÄ‚îÄ process_pdf.py          # Main PDF processing script
‚îÇ   ‚îî‚îÄ‚îÄ debug_mistral.py        # Debug script for API testing
‚îú‚îÄ‚îÄ ocr_fix/                    # Formatting pipeline
‚îÇ   ‚îú‚îÄ‚îÄ stage1.py               # Stage 1: Preprocessing
‚îÇ   ‚îú‚îÄ‚îÄ stage2.py               # Stage 2: LLM-based formatting
‚îÇ   ‚îî‚îÄ‚îÄ fix_markdown.py         # Image link fixing
‚îú‚îÄ‚îÄ txtfiles/                   # Configuration and templates
‚îÇ   ‚îú‚îÄ‚îÄ requirements.md        # Python dependencies
‚îÇ   ‚îú‚îÄ‚îÄ env_template.md        # Environment template
‚îÇ   ‚îî‚îÄ‚îÄ universal_research_prompt.md  # Universal research prompt for Stage 2
‚îú‚îÄ‚îÄ test_pdf/                   # Sample PDF files for testing
‚îú‚îÄ‚îÄ {pdf_name}/                 # Output directory (auto-generated from PDF filename)
‚îÇ   ‚îú‚îÄ‚îÄ document_content.md     # Raw OCR output
‚îÇ   ‚îú‚îÄ‚îÄ pre_stage_1.md         # After image link fixing
‚îÇ   ‚îú‚îÄ‚îÄ stage_1_complete.md    # Stage 1 output
‚îÇ   ‚îú‚îÄ‚îÄ final_formatted.md      # Final formatted output
‚îÇ   ‚îî‚îÄ‚îÄ page_X_image_Y.jpeg    # Extracted images
‚îú‚îÄ‚îÄ example_format_md/          # Example output
‚îÇ   ‚îî‚îÄ‚îÄ formatted_document.md   # Sample formatted document
‚îú‚îÄ‚îÄ test_pdf/                   # Test PDF directory
‚îú‚îÄ‚îÄ venv/                       # Virtual environment
‚îú‚îÄ‚îÄ .env                        # Environment variables (not in repo)
‚îú‚îÄ‚îÄ .gitignore                  # Git ignore rules
‚îî‚îÄ‚îÄ README.md                   # This file
```

## Formatting Features

### Stage 1 Features:
- ‚úÖ **Zero information loss guaranteed**
- **Universal Document Truncation**: Intelligently removes post-references content across different paper structures
- **Enhanced OCR Error Fixes**: Comprehensive repair system including:
  - URL spacing fixes (`https: //` ‚Üí `https://`)
  - Unicode ligature corrections (`Ô¨Å` ‚Üí `fi`, `Ô¨Ç` ‚Üí `fl`)
  - Mathematical expression cleanup (`{{ }}^{{133}}` ‚Üí `^133`)
- **Hybrid Paragraph Reconstruction**: Advanced dual-approach system combining:
  - Comprehensive regex pattern detection for structural elements
  - Line-by-line processing for maintainable control flow
  - Enhanced detection of citations, species names, figure captions, and section headers
- **Content Preservation**: Maintains all tables, equations, references, images, and scientific notation
- **Automatic Path Detection**: Finds and processes the most recent output directory

### Stage 2 Features:
- ‚úÖ **Universal Research Paper Support**: Adapts to any academic discipline automatically
- **Mathematical Expression Enhancement**: Converts LaTeX to proper HTML (`$^{133}$` ‚Üí `<sup>133</sup>`)
- **Scientific Content Formatting**: Proper italicization of gene names, species, etc. (`SCGB3A2` ‚Üí `*SCGB3A2*`)
- **Citation Format Repair**: Fixes malformed references (`^{11--13,26,19,38}` ‚Üí `^11-13,19,26,38`)
- **Figure Reference Creation**: Creates clickable figure links (`![Figure 1](#figure-1)`)
- **Professional Typography**: Smart quotes, proper em-dashes, spacing improvements
- **Section-by-Section Processing**: Handles large documents efficiently without truncation
- **Retry Logic**: 3-attempt processing with exponential backoff for reliability
- **Zero Information Loss**: Fallback mechanisms preserve all content if processing fails

## API Response Structure

The Mistral OCR API returns a structured response:

```python
{
    "pages": [
        {
            "markdown": "Page content in markdown...",
            "images": [
                {
                    "image_base64": "base64_encoded_image_data",
                    "type": "image/jpeg"
                }
            ]
        }
    ]
}
```

## Error Handling

The pipeline includes comprehensive error handling for:
- Missing API keys
- Invalid URLs
- Network timeouts
- API rate limits
- Malformed responses
- LLM processing failures (with retry logic)
- File I/O errors
- Image processing errors

## Debugging Tools

### Debug Mistral API (`ocr_get/debug_mistral.py`)
- Tests Mistral OCR API connectivity
- Saves raw API responses to JSON
- Analyzes image extraction results
- Useful for troubleshooting API issues

### Test Data
- `test.json`: Sample API response for testing
- `document_ocr_test/`: Contains processed outputs for analysis

## Limitations

- Requires internet connection for API calls to Mistral OCR and Google Gemini
- Processing time depends on document size and complexity (typically 2-10 minutes for research papers)
- Stage 2 requires Google Gemini API access with sufficient quota
- Image extraction quality depends on source PDF quality and API response format
- Very large documents (>50 pages) may require extended processing time

## Dependencies

Key Python packages:
- `httpx`: HTTP client for API calls
- `python-dotenv`: Environment variable management
- `google-generativeai`: Gemini AI integration
- `Pillow`: Image processing (if needed)
- `fastapi`, `uvicorn`: Web framework (for future API endpoints)

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## License

All components are part of NUU Cognition. NUU Capture is an element of NUU Cognition.

## Acknowledgments

- Mistral AI for providing the OCR API
- Google Gemini for advanced formatting capabilities
- OpenReview for the test document 